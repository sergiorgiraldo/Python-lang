{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyPI `openplugincore`\n",
        "This is the meat of OpenPlugin, it contains all tools you need to interface with ChatGPT plugins as you do on ChatGPT Pro itself.\n",
        "## Watch out\n",
        "Issues and concerns to look out for\n",
        "- python version : `openplugincore` requires python version >= `3.10`\n",
        "- `You exceeded your current quota` : If your run into an error suggesting `You exceeded your current quota` that could be for several reasons, refer to this [StackOverflow answer](https://stackoverflow.com/a/75898717/9622142) on how to resolve it."
      ],
      "metadata": {
        "id": "10Cn3Kn4Ti7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quickstart\n",
        "1. Install [openplugincore](https://pypi.org/project/openplugincore/)"
      ],
      "metadata": {
        "id": "VOOZLdivTnXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13CphD2hTdTF",
        "outputId": "97f00ff3-0ca0-4069-ce34-6b2abc4fbe6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openplugincore\n",
            "  Downloading openplugincore-0.6.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openplugincore) (2.27.1)\n",
            "Collecting openai (from openplugincore)\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain (from openplugincore)\n",
            "  Downloading langchain-0.0.254-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv (from openplugincore)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->openplugincore) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->openplugincore) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->openplugincore) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->openplugincore) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain->openplugincore)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.11 (from langchain->openplugincore)\n",
            "  Downloading langsmith-0.0.19-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain->openplugincore) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->openplugincore) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain->openplugincore)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->openplugincore) (1.10.12)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->openplugincore) (8.2.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openplugincore) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openplugincore) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->openplugincore) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openplugincore) (3.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai->openplugincore) (4.65.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->openplugincore) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->openplugincore) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->openplugincore) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->openplugincore) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->openplugincore) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain->openplugincore)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain->openplugincore)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain->openplugincore) (4.7.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->openplugincore) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain->openplugincore) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->openplugincore)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, langsmith, openai, dataclasses-json, langchain, openplugincore\n",
            "Successfully installed dataclasses-json-0.5.14 langchain-0.0.254 langsmith-0.0.19 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.27.8 openapi-schema-pydantic-1.2.4 openplugincore-0.6.2 python-dotenv-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openplugincore"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Assign `OPENAI_API_KEY` environment variable with your OpenAI API key"
      ],
      "metadata": {
        "id": "-5nok56rTsEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "os.environ[\"OPENAI_API_KEY\"] = None # add key here"
      ],
      "metadata": {
        "id": "Fci-fzk6TpDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Start using `openplugincore` in your project\n",
        "\n",
        "simplest way to use `openplugincore`"
      ],
      "metadata": {
        "id": "WC1JfG9cTyGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openplugincore import openplugin_completion\n",
        "\n",
        "openplugin_completion_generation = openplugin_completion(\n",
        "    openai_api_key = os.environ[\"OPENAI_API_KEY\"],\n",
        "    plugin_name = \"GifApi\",\n",
        "    truncate = True, # Defaults to True. Truncates the plugin API response to ensure the LLM's token limit is not exceeded\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"show me a gif of a gangster cat\"\n",
        "        }\n",
        "    ],\n",
        "    model = \"gpt-3.5-turbo-0613\",\n",
        "    temperature = 0,\n",
        ")\n",
        "\n",
        "print(json.dumps(openplugin_completion_generation, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4RELLJJTzEz",
        "outputId": "7c41f10c-4167-48a0-b66e-f296077207e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.utilities.openapi:Attempting to load an OpenAPI 3.0.2 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-7ki1flBtfFReBBXNk9ae1Upji7k2M\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1691366679,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"Here are some GIFs of gangster cats:\\n\\n1. ![Cat Spin GIF by Keanu Movie](https://media3.giphy.com/media/l2JJvDhbnoSU9e2hW/giphy.gif)\\n2. ![cat kitten GIF by Romy](https://media4.giphy.com/media/CUFd8c0eovNio/giphy.gif)\\n3. ![confused cat GIF by Keanu Movie](https://media4.giphy.com/media/xT9DPykKHxZy3hhoLm/giphy.gif)\\n4. ![cats gang GIF](https://media4.giphy.com/media/CwWYDU9YQHDnG/giphy.gif)\\n5. ![thug life deal with it GIF by Loly in the sky](https://media4.giphy.com/media/MT9MUfaFZpWufySsmE/giphy.gif)\\n6. ![cat sparkle GIF by Keanu Movie](https://media1.giphy.com/media/l41Ye1pJJLVeGnCXS/giphy.gif)\\n7. ![hip hop dj cat GIF](https://media4.giphy.com/media/T7ukTzXQVmWqI/giphy.gif)\\n8. ![Bad Boy Deal With It GIF by TikTok](https://media3.giphy.com/media/WoRz0xf3fUBWTWXUJ0/giphy.gif)\\n9. ![space cat GIF](https://media4.giphy.com/media/w2JmkbOHFoq8U/giphy.gif)\\n10. ![Bad Boy Deal With It GIF by TikTok](https://media3.giphy.com/media/Ynx9CV7G7uYWpEZU2s/giphy.gif)\\n\\nPlease note that the content of these GIFs may vary, and some may not exactly depict a gangster cat.\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1261,\n",
            "    \"completion_tokens\": 389,\n",
            "    \"total_tokens\": 1650\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "or for more nuanced use"
      ],
      "metadata": {
        "id": "Qftm5HWOUGAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openplugincore import OpenPlugin\n",
        "\n",
        "plugin = OpenPlugin(\"GifApi\", os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"show me a gif of a gangster cat\"\n",
        "    }\n",
        "]\n",
        "\n",
        "function_response = plugin.fetch_plugin(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages = messages,\n",
        "    truncate = True, # Truncates the plugin API response to ensure the LLM's token limit is not exceeded\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "import openai\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "OpenPlugin_generation = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages= messages + [function_response],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(json.dumps(OpenPlugin_generation, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzQyF5ecUGcU",
        "outputId": "712a7a85-3498-4376-ff1c-5ffc457f1c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.utilities.openapi:Attempting to load an OpenAPI 3.0.2 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-7ki33yx0w02BMl3wA5bRc4bJLpRVC\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1691366765,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"Here are some GIFs of gangster cats:\\n\\n1. ![Cat Spin GIF by Keanu Movie](https://media3.giphy.com/media/l2JJvDhbnoSU9e2hW/giphy.gif)\\n2. ![cat kitten GIF by Romy](https://media4.giphy.com/media/CUFd8c0eovNio/giphy.gif)\\n3. ![confused cat GIF by Keanu Movie](https://media4.giphy.com/media/xT9DPykKHxZy3hhoLm/giphy.gif)\\n4. ![cats gang GIF](https://media4.giphy.com/media/CwWYDU9YQHDnG/giphy.gif)\\n5. ![thug life deal with it GIF by Loly in the sky](https://media4.giphy.com/media/MT9MUfaFZpWufySsmE/giphy.gif)\\n6. ![cat sparkle GIF by Keanu Movie](https://media1.giphy.com/media/l41Ye1pJJLVeGnCXS/giphy.gif)\\n7. ![hip hop dj cat GIF](https://media4.giphy.com/media/T7ukTzXQVmWqI/giphy.gif)\\n8. ![Bad Boy Deal With It GIF by TikTok](https://media3.giphy.com/media/WoRz0xf3fUBWTWXUJ0/giphy.gif)\\n9. ![space cat GIF](https://media4.giphy.com/media/w2JmkbOHFoq8U/giphy.gif)\\n10. ![Bad Boy Deal With It GIF by TikTok](https://media3.giphy.com/media/Ynx9CV7G7uYWpEZU2s/giphy.gif)\\n\\nPlease note that the content of these GIFs may vary, and some may not exactly depict a gangster cat.\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1261,\n",
            "    \"completion_tokens\": 389,\n",
            "    \"total_tokens\": 1650\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "and to be respectful to plugin APIs you can use `OpenPluginMemo`"
      ],
      "metadata": {
        "id": "TvnQW5NKUNGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openplugincore import OpenPluginMemo\n",
        "\n",
        "open_plugin_memo = OpenPluginMemo() # Stores the plugin's config in memory so that it does not need to call the API to fetch the config every time the plugin is initialize.\n",
        "open_plugin_memo.init()\n",
        "\n",
        "plugin = open_plugin_memo.get_plugin('GifApi') # returns the plugin if it is already initialized, otherwise returns None\n",
        "if plugin is None: # in this demo it returns None\n",
        "    plugin = open_plugin_memo.init_plugin('GifApi') # initializes the plugin\n",
        "\n",
        "# the rest is the same as using the OpenPlugin class\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"show me a gif of a gangster cat\"\n",
        "    }\n",
        "]\n",
        "\n",
        "function_response = plugin.fetch_plugin(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages = messages,\n",
        "    truncate = True, # Truncates the plugin API response to ensure the LLM's token limit is not exceeded\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "import openai\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "OpenPlugin_generation = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages= messages + [function_response],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(json.dumps(OpenPlugin_generation, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AMkIRaaUKMl",
        "outputId": "c31667ce-0beb-43ba-d597-ca83a5572978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEMO READY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.utilities.openapi:Attempting to load an OpenAPI 3.0.2 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.utilities.openapi:Attempting to load an OpenAPI 3.0.2 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-7ki3Rlo032wj2djLc0GqhWlrgS79L\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1691366789,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"Here are some GIFs of gangster cats:\\n\\n1. ![Cat Spin GIF by Keanu Movie](https://media3.giphy.com/media/l2JJvDhbnoSU9e2hW/giphy.gif)\\n2. ![cat kitten GIF by Romy](https://media4.giphy.com/media/CUFd8c0eovNio/giphy.gif)\\n3. ![confused cat GIF by Keanu Movie](https://media4.giphy.com/media/xT9DPykKHxZy3hhoLm/giphy.gif)\\n4. ![cats gang GIF](https://media4.giphy.com/media/CwWYDU9YQHDnG/giphy.gif)\\n5. ![thug life deal with it GIF by Loly in the sky](https://media4.giphy.com/media/MT9MUfaFZpWufySsmE/giphy.gif)\\n6. ![cat sparkle GIF by Keanu Movie](https://media1.giphy.com/media/l41Ye1pJJLVeGnCXS/giphy.gif)\\n7. ![hip hop dj cat GIF](https://media4.giphy.com/media/T7ukTzXQVmWqI/giphy.gif)\\n8. ![Bad Boy Deal With It GIF by TikTok](https://media3.giphy.com/media/WoRz0xf3fUBWTWXUJ0/giphy.gif)\\n9. ![space cat GIF](https://media4.giphy.com/media/w2JmkbOHFoq8U/giphy.gif)\\n10. ![Bad Boy Deal With It GIF by TikTok](https://media3.giphy.com/media/Ynx9CV7G7uYWpEZU2s/giphy.gif)\\n\\nPlease note that the content of these GIFs may vary, and some may not exactly depict a gangster cat.\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1261,\n",
            "    \"completion_tokens\": 389,\n",
            "    \"total_tokens\": 1650\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7EI0wb34UPzf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
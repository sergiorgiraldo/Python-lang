{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('pedidos_pagseguro.csv', error_bad_lines=False, sep=';');\n",
    "data_text = data[['headline_text']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3985"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of                                           headline_text  index\n",
      "0                                               bla bla      0\n",
      "1                          A máquina está uma porcaria       1\n",
      "2     Estou arrependido ...vcs são péssimos estou aq...      2\n",
      "3     usei menos de um mês precisei de ajuda para co...      3\n",
      "4       demora muito para aceitar o cartão dos clientes      4\n",
      "5     Demora muito para passar a venda aprovada para...      5\n",
      "6     Um sistema mais seguro e melhor suporte ao cli...      6\n",
      "7     Transferir os valores para conta corrente indi...      7\n",
      "8     O suporte é muito fraco, mudei meu plano para ...      8\n",
      "9     A visualizacao diaria ficou muito RUIM. A VISU...      9\n",
      "10              dispor de prestamos quando é nescesario     10\n",
      "11    quando parcelado, depositar parceladamente, as...     11\n",
      "12    comprei a minizinha chip e tinha propaganda de...     12\n",
      "13    moderninha pro muito lenta, wifi fica caindo o...     13\n",
      "14    Demora muito pra cair valor em minha conta pag...     14\n",
      "15          Melhorar suas taxas de juros.É muito altas.     15\n",
      "16                             Baixar um pouco as taxas     16\n",
      "17    cartão ser como débito, ja que só passa se tiv...     17\n",
      "18    Não consigo falar com ninguém, apenas com um r...     18\n",
      "19                   Desburocratização de documentação      19\n",
      "20                                MUITO RUIM E DEMORADO     20\n",
      "21    Entregar a maquiniha quando compramos coisa qu...     21\n",
      "22    treansferir as vendas para contas tanto juridi...     22\n",
      "23    Voces são os pioneiros (banco digital), os mel...     23\n",
      "24                                                 tudo     24\n",
      "25    deixar a gente fazer as perguntas, porque não ...     25\n",
      "26         Alteração de cadastro mais facilitada e ágil     26\n",
      "27                      Bateria da minizinha dura pouco     27\n",
      "28                     bateria deveria durar mais tempo     28\n",
      "29                 Conseguir inserir fotos nos produtos     29\n",
      "...                                                 ...    ...\n",
      "3955                 Tem concorrentes com taxas menores   3955\n",
      "3956  Minha reclamação e quando eu faço uma venda de...   3956\n",
      "3957  Tem uma canta  digital  com cartão de crédito ...   3957\n",
      "3958                                PROPAGANDA ENGANOSA   3958\n",
      "3959  Tenho no cartão um valor de 9,28 não consigo u...   3959\n",
      "3960  Não cobrar os primeiros três meses de taxa ou ...   3960\n",
      "3961                Revejam o atendimento pela central    3961\n",
      "3962  A máquina tem a bateria muito ruim e as vezes ...   3962\n",
      "3963                                                  I   3963\n",
      "3964                                            Entrega   3964\n",
      "3965  Atendimento péssimos desde que comprei não con...   3965\n",
      "3966  Máquina muito lenta fica muito tempo fora de c...   3966\n",
      "3967  Tenho um dinheiro preso nesse e-mail josianetr...   3967\n",
      "3968                                         Empréstimo   3968\n",
      "3969  Porque que o dinheiro que fica na opção a rece...   3969\n",
      "3970  Burocracia enorme pra conseguir transferir o d...   3970\n",
      "3971                        Diminuir a taxa do crédito.   3971\n",
      "3972  Valorizar os pequenos e não apenas grandes fat...   3972\n",
      "3973  Poderia aceitar vale card tb e poderia imprimi...   3973\n",
      "3974  Ter que refazer cadastro para voucher isto errado   3974\n",
      "3975  Na propaganda não é claramente dito que vouche...   3975\n",
      "3976  comprei a maquina com a promessa de isencao na...   3976\n",
      "3977            Renovação de maquinas por mais moderna.   3977\n",
      "3978                         Antecipacao venda digitada   3978\n",
      "3979  Conectividade da maquina ruim quando não esta ...   3979\n",
      "3980        Preciso ter acesso ao endereço do comprador   3980\n",
      "3981                    Diminuir as taxas a sumup tá 1%   3981\n",
      "3982  a máquina deveria quebrar menos, em quatro mes...   3982\n",
      "3983  Deveria passar de 90 dias para 12 meses a susp...   3983\n",
      "3984  Deixar a moderninha funcionando, mesmo se esti...   3984\n",
      "\n",
      "[3985 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "#documents[:5]\n",
    "print(documents.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sgiraldo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sgiraldo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mother in law\n"
     ]
    }
   ],
   "source": [
    "print(WordNetLemmatizer().lemmatize('mother in law', pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemmer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denied</td>\n",
       "      <td>deni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humbled</td>\n",
       "      <td>humbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word stemmed\n",
       "0       caresses  caress\n",
       "1          flies     fli\n",
       "2           dies     die\n",
       "3          mules    mule\n",
       "4         denied    deni\n",
       "5           died     die\n",
       "6         agreed    agre\n",
       "7          owned     own\n",
       "8        humbled   humbl\n",
       "9          sized    size\n",
       "10       meeting    meet\n",
       "11       stating   state\n",
       "12       siezing    siez\n",
       "13   itemization    item\n",
       "14   sensational  sensat\n",
       "15   traditional  tradit\n",
       "16     reference   refer\n",
       "17     colonizer   colon\n",
       "18       plotted    plot"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "pd.DataFrame(data = {'original word': original_words, 'stemmed': singles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['Recebimento', 'na', 'hora', 'pelo', 'cartão', 'pre', 'pago']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['recebimento', 'hora', 'pelo', 'cartão', 'pago']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 2000].values[0][0]\n",
    "\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents['headline_text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   []\n",
       "1                            [máquina, está, porcaria]\n",
       "2    [estou, arrependido, péssimo, estou, aqui, ten...\n",
       "3    [usei, meno, precisei, ajuda, para, continuar,...\n",
       "4       [demora, muito, para, aceitar, cartão, client]\n",
       "5    [demora, muito, para, passar, venda, aprovada,...\n",
       "6       [sistema, mai, seguro, melhor, suport, client]\n",
       "7    [transferir, valor, para, conta, corrent, indi...\n",
       "8    [suport, muito, fraco, mudei, plano, para, rec...\n",
       "9    [visualizacao, diaria, ficou, muito, ruim, vis...\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 está\n",
      "1 máquina\n",
      "2 porcaria\n",
      "3 aqui\n",
      "4 arrependido\n",
      "5 email\n",
      "6 estou\n",
      "7 falando\n",
      "8 indico\n",
      "9 inválido\n",
      "10 merda\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-9d71aaeef1ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbow_corpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocessed_docs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbow_corpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4311\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[4311]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 18 (\"cartão\") appears 1 time.\n",
      "Word 31 (\"hora\") appears 1 time.\n",
      "Word 42 (\"recebimento\") appears 1 time.\n",
      "Word 117 (\"pelo\") appears 1 time.\n",
      "Word 127 (\"pago\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_2000 = bow_corpus[2000]\n",
    "\n",
    "for i in range(len(bow_doc_2000)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_2000[i][0], \n",
    "                                                     dictionary[bow_doc_2000[i][0]], \n",
    "                                                     bow_doc_2000[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.058*\"taxa\" + 0.054*\"para\" + 0.040*\"máquina\" + 0.029*\"mai\" + 0.027*\"client\" + 0.024*\"muito\" + 0.021*\"minha\" + 0.020*\"juro\" + 0.017*\"alta\" + 0.016*\"outra\"\n",
      "Topic: 1 \n",
      "Words: 0.057*\"venda\" + 0.050*\"client\" + 0.031*\"muito\" + 0.026*\"atendimento\" + 0.024*\"cartão\" + 0.020*\"para\" + 0.018*\"valor\" + 0.018*\"taxa\" + 0.016*\"compra\" + 0.015*\"mai\"\n",
      "Topic: 2 \n",
      "Words: 0.090*\"taxa\" + 0.026*\"recarga\" + 0.025*\"pagamento\" + 0.024*\"celular\" + 0.023*\"muito\" + 0.021*\"problema\" + 0.020*\"conta\" + 0.019*\"venda\" + 0.016*\"client\" + 0.016*\"melhor\"\n",
      "Topic: 3 \n",
      "Words: 0.067*\"para\" + 0.034*\"receb\" + 0.030*\"minha\" + 0.026*\"conta\" + 0.023*\"venda\" + 0.021*\"mai\" + 0.019*\"taxa\" + 0.019*\"transferência\" + 0.016*\"mesmo\" + 0.015*\"está\"\n",
      "Topic: 4 \n",
      "Words: 0.057*\"muito\" + 0.046*\"para\" + 0.033*\"minha\" + 0.033*\"conta\" + 0.032*\"cartão\" + 0.029*\"taxa\" + 0.023*\"crédito\" + 0.021*\"alta\" + 0.020*\"bateria\" + 0.018*\"venda\"\n",
      "Topic: 5 \n",
      "Words: 0.050*\"cartão\" + 0.036*\"para\" + 0.028*\"máquina\" + 0.025*\"valor\" + 0.024*\"receb\" + 0.022*\"dinheiro\" + 0.021*\"hora\" + 0.020*\"sinal\" + 0.019*\"problema\" + 0.018*\"venda\"\n",
      "Topic: 6 \n",
      "Words: 0.071*\"mai\" + 0.050*\"bateria\" + 0.041*\"maquina\" + 0.036*\"muito\" + 0.035*\"venda\" + 0.026*\"máquina\" + 0.019*\"dia\" + 0.016*\"conta\" + 0.015*\"minha\" + 0.015*\"valor\"\n",
      "Topic: 7 \n",
      "Words: 0.040*\"conta\" + 0.037*\"pagamento\" + 0.031*\"melhorar\" + 0.025*\"para\" + 0.024*\"tenho\" + 0.023*\"mai\" + 0.022*\"client\" + 0.021*\"venda\" + 0.020*\"taxa\" + 0.019*\"receb\"\n",
      "Topic: 8 \n",
      "Words: 0.038*\"para\" + 0.038*\"venda\" + 0.035*\"conta\" + 0.030*\"muito\" + 0.020*\"dinheiro\" + 0.018*\"maquina\" + 0.018*\"estou\" + 0.017*\"pagar\" + 0.016*\"pelo\" + 0.015*\"aplicativo\"\n",
      "Topic: 9 \n",
      "Words: 0.084*\"taxa\" + 0.038*\"conta\" + 0.034*\"para\" + 0.029*\"valor\" + 0.025*\"outra\" + 0.023*\"máquina\" + 0.019*\"receb\" + 0.015*\"mai\" + 0.015*\"pagar\" + 0.014*\"muito\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Can you distinguish different topics using the words in each topic and their corresponding weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.024*\"valor\" + 0.020*\"mai\" + 0.017*\"conta\" + 0.016*\"para\" + 0.015*\"taxa\" + 0.015*\"cartão\" + 0.014*\"pagar\" + 0.014*\"saldo\" + 0.014*\"minizinha\" + 0.013*\"isso\"\n",
      "Topic: 1 Word: 0.037*\"receb\" + 0.032*\"venda\" + 0.020*\"mesmo\" + 0.019*\"recarga\" + 0.018*\"taxa\" + 0.017*\"baixar\" + 0.017*\"celular\" + 0.017*\"para\" + 0.016*\"muito\" + 0.015*\"funciona\"\n",
      "Topic: 2 Word: 0.035*\"taxa\" + 0.028*\"pagamento\" + 0.023*\"conta\" + 0.021*\"para\" + 0.019*\"diminuir\" + 0.019*\"valor\" + 0.017*\"transferência\" + 0.013*\"poder\" + 0.013*\"menor\" + 0.013*\"fazer\"\n",
      "Topic: 3 Word: 0.025*\"crédito\" + 0.023*\"atendimento\" + 0.019*\"parcelado\" + 0.018*\"bateria\" + 0.017*\"moderninha\" + 0.014*\"receb\" + 0.014*\"débito\" + 0.013*\"mai\" + 0.013*\"facilitar\" + 0.013*\"para\"\n",
      "Topic: 4 Word: 0.059*\"bateria\" + 0.027*\"maquina\" + 0.025*\"conta\" + 0.024*\"muito\" + 0.022*\"pagar\" + 0.021*\"melhorar\" + 0.020*\"máquina\" + 0.016*\"pelo\" + 0.016*\"taxa\" + 0.016*\"dura\"\n",
      "Topic: 5 Word: 0.052*\"taxa\" + 0.042*\"alta\" + 0.036*\"muito\" + 0.025*\"problema\" + 0.023*\"conta\" + 0.018*\"para\" + 0.017*\"mai\" + 0.016*\"empréstimo\" + 0.014*\"cartão\" + 0.013*\"minha\"\n",
      "Topic: 6 Word: 0.031*\"para\" + 0.030*\"client\" + 0.028*\"taxa\" + 0.026*\"venda\" + 0.020*\"valor\" + 0.017*\"parcelamento\" + 0.016*\"bateria\" + 0.015*\"melhorar\" + 0.014*\"você\" + 0.014*\"estou\"\n",
      "Topic: 7 Word: 0.033*\"parcelamento\" + 0.033*\"juro\" + 0.032*\"aceitar\" + 0.028*\"taxa\" + 0.018*\"menor\" + 0.018*\"muito\" + 0.015*\"alta\" + 0.015*\"tenho\" + 0.015*\"pagamento\" + 0.014*\"cobrar\"\n",
      "Topic: 8 Word: 0.032*\"máquina\" + 0.030*\"mai\" + 0.024*\"client\" + 0.023*\"taxa\" + 0.020*\"melhor\" + 0.019*\"maquina\" + 0.018*\"tudo\" + 0.015*\"cobrada\" + 0.015*\"para\" + 0.014*\"muito\"\n",
      "Topic: 9 Word: 0.020*\"para\" + 0.017*\"dinheiro\" + 0.015*\"receb\" + 0.014*\"fazer\" + 0.014*\"maquininha\" + 0.014*\"taxa\" + 0.013*\"tempo\" + 0.013*\"aplicativo\" + 0.013*\"venda\" + 0.013*\"minha\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation by classifying sample document using LDA Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recebimento', 'hora', 'pelo', 'cartão', 'pago']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.8499724268913269\t \n",
      "Topic: 0.050*\"cartão\" + 0.036*\"para\" + 0.028*\"máquina\" + 0.025*\"valor\" + 0.024*\"receb\" + 0.022*\"dinheiro\" + 0.021*\"hora\" + 0.020*\"sinal\" + 0.019*\"problema\" + 0.018*\"venda\"\n",
      "\n",
      "Score: 0.01667613908648491\t \n",
      "Topic: 0.038*\"para\" + 0.038*\"venda\" + 0.035*\"conta\" + 0.030*\"muito\" + 0.020*\"dinheiro\" + 0.018*\"maquina\" + 0.018*\"estou\" + 0.017*\"pagar\" + 0.016*\"pelo\" + 0.015*\"aplicativo\"\n",
      "\n",
      "Score: 0.016670236364006996\t \n",
      "Topic: 0.040*\"conta\" + 0.037*\"pagamento\" + 0.031*\"melhorar\" + 0.025*\"para\" + 0.024*\"tenho\" + 0.023*\"mai\" + 0.022*\"client\" + 0.021*\"venda\" + 0.020*\"taxa\" + 0.019*\"receb\"\n",
      "\n",
      "Score: 0.01666978932917118\t \n",
      "Topic: 0.057*\"venda\" + 0.050*\"client\" + 0.031*\"muito\" + 0.026*\"atendimento\" + 0.024*\"cartão\" + 0.020*\"para\" + 0.018*\"valor\" + 0.018*\"taxa\" + 0.016*\"compra\" + 0.015*\"mai\"\n",
      "\n",
      "Score: 0.01666942797601223\t \n",
      "Topic: 0.071*\"mai\" + 0.050*\"bateria\" + 0.041*\"maquina\" + 0.036*\"muito\" + 0.035*\"venda\" + 0.026*\"máquina\" + 0.019*\"dia\" + 0.016*\"conta\" + 0.015*\"minha\" + 0.015*\"valor\"\n",
      "\n",
      "Score: 0.016669420525431633\t \n",
      "Topic: 0.057*\"muito\" + 0.046*\"para\" + 0.033*\"minha\" + 0.033*\"conta\" + 0.032*\"cartão\" + 0.029*\"taxa\" + 0.023*\"crédito\" + 0.021*\"alta\" + 0.020*\"bateria\" + 0.018*\"venda\"\n",
      "\n",
      "Score: 0.016668986529111862\t \n",
      "Topic: 0.058*\"taxa\" + 0.054*\"para\" + 0.040*\"máquina\" + 0.029*\"mai\" + 0.027*\"client\" + 0.024*\"muito\" + 0.021*\"minha\" + 0.020*\"juro\" + 0.017*\"alta\" + 0.016*\"outra\"\n",
      "\n",
      "Score: 0.016668111085891724\t \n",
      "Topic: 0.090*\"taxa\" + 0.026*\"recarga\" + 0.025*\"pagamento\" + 0.024*\"celular\" + 0.023*\"muito\" + 0.021*\"problema\" + 0.020*\"conta\" + 0.019*\"venda\" + 0.016*\"client\" + 0.016*\"melhor\"\n",
      "\n",
      "Score: 0.01666804403066635\t \n",
      "Topic: 0.084*\"taxa\" + 0.038*\"conta\" + 0.034*\"para\" + 0.029*\"valor\" + 0.025*\"outra\" + 0.023*\"máquina\" + 0.019*\"receb\" + 0.015*\"mai\" + 0.015*\"pagar\" + 0.014*\"muito\"\n",
      "\n",
      "Score: 0.016667423769831657\t \n",
      "Topic: 0.067*\"para\" + 0.034*\"receb\" + 0.030*\"minha\" + 0.026*\"conta\" + 0.023*\"venda\" + 0.021*\"mai\" + 0.019*\"taxa\" + 0.019*\"transferência\" + 0.016*\"mesmo\" + 0.015*\"está\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[2000]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test document has the highest probability to be part of the topic on the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation by classifying sample document using LDA TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.6200292110443115\t \n",
      "Topic: 0.035*\"taxa\" + 0.028*\"pagamento\" + 0.023*\"conta\" + 0.021*\"para\" + 0.019*\"diminuir\" + 0.019*\"valor\" + 0.017*\"transferência\" + 0.013*\"poder\" + 0.013*\"menor\" + 0.013*\"fazer\"\n",
      "\n",
      "Score: 0.2466115802526474\t \n",
      "Topic: 0.037*\"receb\" + 0.032*\"venda\" + 0.020*\"mesmo\" + 0.019*\"recarga\" + 0.018*\"taxa\" + 0.017*\"baixar\" + 0.017*\"celular\" + 0.017*\"para\" + 0.016*\"muito\" + 0.015*\"funciona\"\n",
      "\n",
      "Score: 0.016672257333993912\t \n",
      "Topic: 0.059*\"bateria\" + 0.027*\"maquina\" + 0.025*\"conta\" + 0.024*\"muito\" + 0.022*\"pagar\" + 0.021*\"melhorar\" + 0.020*\"máquina\" + 0.016*\"pelo\" + 0.016*\"taxa\" + 0.016*\"dura\"\n",
      "\n",
      "Score: 0.016671443358063698\t \n",
      "Topic: 0.052*\"taxa\" + 0.042*\"alta\" + 0.036*\"muito\" + 0.025*\"problema\" + 0.023*\"conta\" + 0.018*\"para\" + 0.017*\"mai\" + 0.016*\"empréstimo\" + 0.014*\"cartão\" + 0.013*\"minha\"\n",
      "\n",
      "Score: 0.01667047291994095\t \n",
      "Topic: 0.031*\"para\" + 0.030*\"client\" + 0.028*\"taxa\" + 0.026*\"venda\" + 0.020*\"valor\" + 0.017*\"parcelamento\" + 0.016*\"bateria\" + 0.015*\"melhorar\" + 0.014*\"você\" + 0.014*\"estou\"\n",
      "\n",
      "Score: 0.016669929027557373\t \n",
      "Topic: 0.020*\"para\" + 0.017*\"dinheiro\" + 0.015*\"receb\" + 0.014*\"fazer\" + 0.014*\"maquininha\" + 0.014*\"taxa\" + 0.013*\"tempo\" + 0.013*\"aplicativo\" + 0.013*\"venda\" + 0.013*\"minha\"\n",
      "\n",
      "Score: 0.016668949276208878\t \n",
      "Topic: 0.025*\"crédito\" + 0.023*\"atendimento\" + 0.019*\"parcelado\" + 0.018*\"bateria\" + 0.017*\"moderninha\" + 0.014*\"receb\" + 0.014*\"débito\" + 0.013*\"mai\" + 0.013*\"facilitar\" + 0.013*\"para\"\n",
      "\n",
      "Score: 0.01666887290775776\t \n",
      "Topic: 0.024*\"valor\" + 0.020*\"mai\" + 0.017*\"conta\" + 0.016*\"para\" + 0.015*\"taxa\" + 0.015*\"cartão\" + 0.014*\"pagar\" + 0.014*\"saldo\" + 0.014*\"minizinha\" + 0.013*\"isso\"\n",
      "\n",
      "Score: 0.01666872203350067\t \n",
      "Topic: 0.033*\"parcelamento\" + 0.033*\"juro\" + 0.032*\"aceitar\" + 0.028*\"taxa\" + 0.018*\"menor\" + 0.018*\"muito\" + 0.015*\"alta\" + 0.015*\"tenho\" + 0.015*\"pagamento\" + 0.014*\"cobrar\"\n",
      "\n",
      "Score: 0.01666855253279209\t \n",
      "Topic: 0.032*\"máquina\" + 0.030*\"mai\" + 0.024*\"client\" + 0.023*\"taxa\" + 0.020*\"melhor\" + 0.019*\"maquina\" + 0.018*\"tudo\" + 0.015*\"cobrada\" + 0.015*\"para\" + 0.014*\"muito\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[2000]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test document has the highest probability to be part of the topic on the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8199552893638611\t Topic: 0.084*\"taxa\" + 0.038*\"conta\" + 0.034*\"para\" + 0.029*\"valor\" + 0.025*\"outra\"\n",
      "Score: 0.020010417327284813\t Topic: 0.058*\"taxa\" + 0.054*\"para\" + 0.040*\"máquina\" + 0.029*\"mai\" + 0.027*\"client\"\n",
      "Score: 0.02000858634710312\t Topic: 0.057*\"muito\" + 0.046*\"para\" + 0.033*\"minha\" + 0.033*\"conta\" + 0.032*\"cartão\"\n",
      "Score: 0.02000555396080017\t Topic: 0.090*\"taxa\" + 0.026*\"recarga\" + 0.025*\"pagamento\" + 0.024*\"celular\" + 0.023*\"muito\"\n",
      "Score: 0.020004678517580032\t Topic: 0.038*\"para\" + 0.038*\"venda\" + 0.035*\"conta\" + 0.030*\"muito\" + 0.020*\"dinheiro\"\n",
      "Score: 0.020004356279969215\t Topic: 0.071*\"mai\" + 0.050*\"bateria\" + 0.041*\"maquina\" + 0.036*\"muito\" + 0.035*\"venda\"\n",
      "Score: 0.020003823563456535\t Topic: 0.057*\"venda\" + 0.050*\"client\" + 0.031*\"muito\" + 0.026*\"atendimento\" + 0.024*\"cartão\"\n",
      "Score: 0.020003529265522957\t Topic: 0.040*\"conta\" + 0.037*\"pagamento\" + 0.031*\"melhorar\" + 0.025*\"para\" + 0.024*\"tenho\"\n",
      "Score: 0.020002011209726334\t Topic: 0.050*\"cartão\" + 0.036*\"para\" + 0.028*\"máquina\" + 0.025*\"valor\" + 0.024*\"receb\"\n",
      "Score: 0.02000172808766365\t Topic: 0.067*\"para\" + 0.034*\"receb\" + 0.030*\"minha\" + 0.026*\"conta\" + 0.023*\"venda\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = 'Vocês cobram muito caro'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

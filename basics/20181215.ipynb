{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.tools.set_credentials_file(username='sergiorgiraldo', api_key='tV59IRMOvDbx7wTMvsGz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reading, Writing, and Creating data\n",
    "Pandas let you use your data from multiple formats like CSV, EXCEL, JSON etc.\n",
    "\n",
    "You can use the data file on your local system or from an external URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create data**\n",
    "\n",
    "DataFrame is the most commonly used data-structure of Pandas, it's a 2-dimensional table like structure that can hold columns of multiple data-types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['Mathematics', 'English', 'History', 'Science', 'Arts', 'Chemistry']\n",
    "marks = [67, 60, 36, 61, 58, 79]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Python's **zip** function, we can merge these two **list** sequences into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x1a51faebd88>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marks_dataset = zip(subjects, marks)\n",
    "marks_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>History</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Science</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arts</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chemistry</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Subjects  Marks\n",
       "0  Mathematics     67\n",
       "1      English     60\n",
       "2      History     36\n",
       "3      Science     61\n",
       "4         Arts     58\n",
       "5    Chemistry     79"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marks_df = pd.DataFrame(list(marks_dataset), columns=['Subjects', 'Marks'])\n",
    "marks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **columns** argument list represents the labels of the respective columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Marks Distribution**\n",
    "\n",
    "The following bar chart represents the marks distribution per subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~sergiorgiraldo/22.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "marks_data = [go.Bar(x=marks_df.Subjects, y=marks_df.Marks)]\n",
    "\n",
    "py.iplot({ 'data': marks_data,\n",
    "            'layout': {\n",
    "               'title': 'Marks Distribution',\n",
    "               'xaxis': {\n",
    "                 'title': 'Subjects'},\n",
    "               'yaxis': {\n",
    "                'title': 'Marks '}\n",
    "        }})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a new column 'Result' using **numpy.where**, set it as 'Pass' if **marks>=40** else 'Fail'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Marks</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>67</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>60</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>History</td>\n",
       "      <td>36</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Science</td>\n",
       "      <td>61</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arts</td>\n",
       "      <td>58</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chemistry</td>\n",
       "      <td>79</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Subjects  Marks Result\n",
       "0  Mathematics     67   Pass\n",
       "1      English     60   Pass\n",
       "2      History     36   Fail\n",
       "3      Science     61   Pass\n",
       "4         Arts     58   Pass\n",
       "5    Chemistry     79   Pass"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marks_df['Result'] = np.where(marks_df['Marks']>=40, 'Pass', 'Fail')\n",
    "marks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete a column (say 'Result'), we can use **`marks_df.pop('Result')`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write data**\n",
    "\n",
    "We can write the **DataFrame** object to different file types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the marks dataframe to a csv(comma-separated values) file in your directory\n",
    "marks_df.to_csv('marks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument **index=False** is to prevent writing the index for each row (0...4) in file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read data**\n",
    "\n",
    "Here, we will be using the [YouTube Channel Dataset.](https://gist.github.com/pravj/9ae9e67d10668c60545e2b858753415c)\n",
    "\n",
    "**Note:- Some of the \"Views\" and \"Comments\" columns have missing values, represented as -1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file from https://gist.github.com/pravj/9ae9e67d10668c60545e2b858753415c\n",
    "channels_df = pd.read_csv('yt-channels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting and Filtering dataframes\n",
    "You can use the describe mehod to show statistics of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Views</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>362.000000</td>\n",
       "      <td>362.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>288.229282</td>\n",
       "      <td>17.383978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>147.604341</td>\n",
       "      <td>12.479304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>172.750000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>295.500000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>399.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>533.000000</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Views    Comments\n",
       "count  362.000000  362.000000\n",
       "mean   288.229282   17.383978\n",
       "std    147.604341   12.479304\n",
       "min     -1.000000   -1.000000\n",
       "25%    172.750000    8.000000\n",
       "50%    295.500000   14.000000\n",
       "75%    399.000000   26.000000\n",
       "max    533.000000   54.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customer Reach Comparison between \"WorldNews\" and \"WorldWeather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Comments</th>\n",
       "      <th colspan=\"8\" halign=\"left\">Views</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Channel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WorldNews</th>\n",
       "      <td>181.0</td>\n",
       "      <td>16.182320</td>\n",
       "      <td>11.131283</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>288.348066</td>\n",
       "      <td>151.969936</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WorldWeather</th>\n",
       "      <td>181.0</td>\n",
       "      <td>18.585635</td>\n",
       "      <td>13.620638</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>288.110497</td>\n",
       "      <td>143.527810</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>532.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Comments                                                    \\\n",
       "                count       mean        std  min  25%   50%   75%   max   \n",
       "Channel                                                                   \n",
       "WorldNews       181.0  16.182320  11.131283 -1.0  7.0  13.0  24.0  54.0   \n",
       "WorldWeather    181.0  18.585635  13.620638 -1.0  8.0  15.0  28.0  53.0   \n",
       "\n",
       "              Views                                                           \n",
       "              count        mean         std  min    25%    50%    75%    max  \n",
       "Channel                                                                       \n",
       "WorldNews     181.0  288.348066  151.969936 -1.0  154.0  294.0  405.0  533.0  \n",
       "WorldWeather  181.0  288.110497  143.527810 -1.0  180.0  296.0  394.0  532.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reach_df = channels_df.groupby('Channel').describe()\n",
    "reach_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice that it's a MultiIndex DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "channels2 = []\n",
    "\n",
    "views_reach_data2, comments_reach_data2 = [], []\n",
    "views_mean2, comments_mean2 = [], []\n",
    "\n",
    "for channel, new_df in reach_df.groupby(level=0):\n",
    "    if not channel in channels2: \n",
    "        channels2.append(channel)\n",
    "    \n",
    "    for col in new_df.columns:\n",
    "        new_col = new_df[col]\n",
    "        print(type(new_col[channel]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9eca51a7c93f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# using the Box method of Plotly's graph objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_col\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_col\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# to prepare two different plots for each section ('views', 'comments')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "channels = []\n",
    "\n",
    "views_reach_data, comments_reach_data = [], []\n",
    "views_mean, comments_mean = [], []\n",
    "\n",
    "# MultiIndex DataFrame Iteration\n",
    "for channel, new_df in reach_df.groupby(level=0):\n",
    "    if not channel in channels: \n",
    "        channels.append(channel)\n",
    "    \n",
    "    for col in new_df.columns:\n",
    "        new_col = new_df[col][channel]\n",
    "        x_label = channel\n",
    "        \n",
    "        # using the Box method of Plotly's graph objects\n",
    "        box = go.Box(y=[new_col['min'], new_col['max']], name=x_label)\n",
    "        \n",
    "        # to prepare two different plots for each section ('views', 'comments')\n",
    "        if (col == 'Views'):\n",
    "            views_reach_data.append(box)\n",
    "            views_mean.append(new_col['mean'])\n",
    "        elif (col == 'Comments'):\n",
    "            comments_reach_data.append(box)\n",
    "            comments_mean.append(new_col['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lines for 'mean' value of 'views'\n",
    "views_reach_data.append(go.Scatter(x=channels, y=views_mean, mode='lines', name='mean'))\n",
    "\n",
    "py.iplot({\n",
    "        'data': views_reach_data,\n",
    "        'layout': {\n",
    "            'title': 'Views Comparison',\n",
    "            'xaxis': {'title': 'Channels'},\n",
    "            'yaxis': {'title': 'Views'}\n",
    "        }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lines for 'mean' values of 'comments'\n",
    "comments_reach_data.append(go.Scatter(x=channels, y=comments_mean, mode='lines', name='mean'))\n",
    "\n",
    "py.iplot({\n",
    "        'data': comments_reach_data,\n",
    "        'layout': {\n",
    "            'title': 'Comments Comparison',\n",
    "            'xaxis': {'title': 'Channels'},\n",
    "            'yaxis': {'title': 'Comments'}\n",
    "}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace the missing data values **(-1)** with **NaN** for some statistical ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_df = channels_df.replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`head` method select top 5 row for the dataframe. (`tail` method will return last 5 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select rows only for the 'WorldNews' channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_df = channels_df[channels_df['Channel'] == 'WorldNews']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select some sample rows from the new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out the rows for 'WorldNews' channel having less than 100 views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_less_views_df = worldnews_df[worldnews_df['Views'] < 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the days when 'WorldNews' has received less than 100 views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_less_views_df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get and set subsets of data object, Pandas supports 3 types of multi-axis indexing.\n",
    "\n",
    "* **loc**\n",
    "    * It is based on the index *labels*.\n",
    "* **iloc**\n",
    "    * It is based on the index *positions*, only integer values are accepted.\n",
    "* **ix**\n",
    "    * Generally it behaves like **loc** but falls back to **iloc** when the label is not present in the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset the index contains only integer values, so all these methods will work similarly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:- The DataFrame *worldnews_df* contains only even integers in the index.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "worldnews_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection By Label**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **label based indexing**, it follows **strict inclusion**. For example **[10:14]** will look for every value in between 10 and 14 including both. **At least 1** labels should be present in the index, otherwise a **KerError** will be raised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return the top **3** rows having index as 0, 2, and 4; Because it looks at the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_df.loc[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection By Position**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **integer based indexing**, it follows **0-based** slicing similar to Python lists that you are used to. Where the starting bound is included but the upper bound is excluded. Using a non-integer, even a valid label will raise a **IndexError**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, this will return the top **4** rows, Because it looks at the positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_df.iloc[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will work like **loc** because the index contains integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_df.ix[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping, Aggregating, and Pivoting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grouping**\n",
    "\n",
    "We can group (combine) the dataset based on certain parameters. For example, here we are grouping the 'WorldNews' dataset based on their 'Anchor' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_anchors_group = worldnews_df.groupby(worldnews_df['Anchor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return a **DataFrameGroupBy** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(worldnews_anchors_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aggregating**\n",
    "\n",
    "Aggregating the resultant group will count the respective 'Views' and 'Columns' for each anchor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_anchors_group.aggregate(np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Views and Comments Share per Anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we take the aggregation information as a DataFrame\n",
    "share_df = worldnews_anchors_group.aggregate(np.sum)\n",
    "anchors = share_df.index\n",
    "\n",
    "# for each sections ('views', 'comments') update the data accordingly\n",
    "share_data = [\n",
    "    {\n",
    "        'values': share_df['Views'],\n",
    "        'labels': anchors,\n",
    "        'domain': {'x': [0, .48]},\n",
    "        'name': 'Views',\n",
    "        'hoverinfo': 'label+value+name',\n",
    "        'hole': 0.4,\n",
    "        'type': 'pie'\n",
    "    },\n",
    "    {\n",
    "        'values': share_df['Comments'],\n",
    "        'labels': anchors,\n",
    "        'domain': {'x': [0.52, 1]},\n",
    "        'name': 'Comments',\n",
    "        'hoverinfo': 'label+value+name',\n",
    "        'hole': 0.4,\n",
    "        'type': 'pie'\n",
    "    }\n",
    "]\n",
    "\n",
    "layout = {\n",
    "    'title': 'Views and Comments Share per Anchor [WorldNews]',\n",
    "    'annotations': [\n",
    "        {\n",
    "            'text': 'Views',\n",
    "            'font': {'size': 15},\n",
    "            'x': 0.21,\n",
    "            'y': 0.5,\n",
    "            'showarrow': False\n",
    "        },\n",
    "        {\n",
    "            'text': 'Comments',\n",
    "            'font': {'size': 15},\n",
    "            'x': 0.81,\n",
    "            'y': 0.5,\n",
    "            'showarrow': False\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "py.iplot({'data': share_data, 'layout': layout})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pivoting**\n",
    "\n",
    "Using the pivot function, we can generate a new table from the original one.\n",
    "\n",
    "It takes three arguments, that decides the **index**, **columns**, and **cell values** of the new table we want.\n",
    "\n",
    "Consider this sample table for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_df.groupby(['Anchor', 'Date']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try reshaping this table to find out how many 'Views' each anchor has received.\n",
    "\n",
    "So we will create a new table whose 'index' is 'Date', 'columns' will be different values of 'Anchor column'.\n",
    "\n",
    "The cell values will be the respective value of the 'Views' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "worldnews_pivoted_df = worldnews_df.pivot(index='Date', columns='Anchor', values='Views')\n",
    "worldnews_pivoted_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our derived table, you can see how many views different anchors have received.\n",
    "\n",
    "Similarly you can reshape your tables according to your usecase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes your dataset has missing values in it.Pandas provide the **interpolate** function to insert data between fixed points. It uses different methods to regularize the missing values, by default it uses **linear interpolation** for the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the absent values (**NaN**) using the **isnull** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's interpolate the Series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_interpolated_df = worldnews_df.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After interpolation, we can see that there are no more **NaN** values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_interpolated_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides multiple methods to easily combine DataFrame and Series objects, like we see in SQL's join operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider these two small DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adf = worldnews_df.iloc[3:8]\n",
    "Bdf = channels_df[channels_df['Channel'] == 'WorldWeather'].iloc[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concat**\n",
    "\n",
    "This function performs the concatenation operation along a given axis. *axis=0* means the operation will be performed along the *rows*, and for *axis=1* it will be along columns. (By default, it's acted along *rows*, ie *axis=0*.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([Adf, Bdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([Adf, Bdf], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join**\n",
    "\n",
    "Pandas provides a single function, **merge**, for all standard join operations between DataFrame objects. We will look the basic arguments for this function.\n",
    "\n",
    "```python\n",
    "merge(left, right, how='inner', on=None)\n",
    "```\n",
    "\n",
    "* **left** - A DataFrame object\n",
    "* **right** - Another DataFrame to combine with.\n",
    "* **how** - Type of join operation, defaults to *inner*. Can be one of *left*, *right*, *inner*, and *outer*.\n",
    "* **on** - Columns names on which the join operation will be performed. Must be available in both the left and right DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inner Join**\n",
    "\n",
    "By default, **join** operates like the **inner join** of SQL. Here, we are performing the join on the 'Date' column.\n",
    "Uses intersection of keys from both the DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get 3 rows because in the 'Date' columns there are only three matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(Adf, Bdf, on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Left Outer Join**\n",
    "\n",
    "Uses the keys from left DataFrame only.\n",
    "\n",
    "```python\n",
    "how='left'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for the 'Date' values '2015-01-04' and '2015-01-05', there is not any corresponding matches **(NaN)** in the right DataFrame.\n",
    "\n",
    "Because these rows are not present in the right DataFrame, **Bdf**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(Adf, Bdf, how='left', on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Right Outer Join**\n",
    "\n",
    "Uses the keys from right DataFrame only.\n",
    "\n",
    "```python\n",
    "how='right'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(Adf, Bdf, how='right', on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Full Outer Join**\n",
    "\n",
    "Uses the intersection of keys from both DataFrames.\n",
    "\n",
    "```python\n",
    "how='outer'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(Adf, Bdf, how='outer', on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data: Dates, Strings, and Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our data to be in the cleanest form, so that we can use it further. For this, we need to get it in the desired structure, that's called cleaning the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Numerical Formatting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the interpolated DataFrame result? You can notice that the resultant values are **Float64** type.\n",
    "\n",
    "Some of the values are like 11.5, 7.5 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(worldnews_interpolated_df['Comments'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know that 'Views' or 'Comments' should be a perfect number by definition. We can format them by applying the ceil function on the 'Comments' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_interpolated_df['Comments'] = worldnews_interpolated_df['Comments'].apply(np.ceil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That will map a number to the smallest integer greater than or equal to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dates Formatting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Series objects in the column 'Date' are 'str' types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(worldnews_df['Date'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the **to_datetime** function to convert them into 'Timestamp' type. The 'format' argument can be used to define the format of date in the 'Series', '2015-01-01' matches with '%Y-%m-%d'.\n",
    "\n",
    "This can be used to timestamp related calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "worldnews_df.loc[:, 'Date'] = pd.to_datetime(worldnews_df['Date'], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(worldnews_df['Date'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also provides functinoality equivalent to \"datetime.timedelta\", which is called \"Timedelta\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_a = worldnews_df['Date'][0]\n",
    "time_b = worldnews_df['Date'][2]\n",
    "\n",
    "time_diff = time_b - time_a\n",
    "type(time_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can collect different components of \"Timedelta\" object like \"days\", \"hours\", \"minutes\" etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diff.components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** String Formatting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provide you a lot of [string formatting](http://pandas.pydata.org/pandas-docs/stable/api.html#string-handling) methods. You can count the occurence of a particular pattern in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_df['Anchor'].str.count('jenn').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the **unique** method you can check that different values in a column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe that the name of 'Anchor' is in smallcase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_df['Anchor'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the **capitalize** method, we can format the string values. There are other methods such as **upper**, **lower** etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_df['Anchor'].str.capitalize().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose that there was a problem in data collection, the name of an anchor was \"Matt\" instead of \"Bob\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do have a method for this situation too, **replace**. Taking arguments as the \"pattern\" and \"expected replacing string\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldnews_df['Anchor'].apply(lambda s: s.replace('bob', 'matt')).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML('<link href=\"//fonts.googleapis.com/css?family=Open+Sans:600,400,300,200|Inconsolata|Ubuntu+Mono:400,700rel=\"stylesheet\" type=\"text/css\" />'))\n",
    "display(HTML('<link rel=\"stylesheet\" type=\"text/csshref=\"http://help.plot.ly/documentation/all_static/css/ipython-notebook-custom.css\">'))\n",
    "\n",
    "! pip install git+https://github.com/plotly/publisher.git --upgrade\n",
    "\n",
    "import publisher\n",
    "publisher.publish(\n",
    "    'Pandas-101.ipynb', '/pandas/intro-to-pandas-tutorial/', 'Pandas 101 | plotly',\n",
    "    'How to use Pandas, the Python data analysis tools, to manipulate and analyse data in plotly.',\n",
    "    title = 'Pandas 101 | plotly',\n",
    "    name = 'Pandas 101',\n",
    "    has_thumbnail='false',\n",
    "    language='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
